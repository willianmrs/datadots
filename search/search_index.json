{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to DataDots Tech Hub","text":"<p>Hello, and welcome to my corner of the internet! I'm Willian Moreira, a passionate technologist with a keen interest in the forefront of digital innovation. This website is my digital garden, a place where I cultivate and share comprehensive tutorials, insightful thoughts, and explorations in the realms of distributed computing, artificial intelligence (including machine learning), and large language models (LLMs).</p> <p>My journey through technology has always been driven by a deep curiosity and the relentless pursuit of knowledge. Here, I aim to demystify complex concepts, share practical insights, and discuss the latest trends that are shaping our digital future. Whether you're a student, professional, or enthusiast eager to learn about Spark and distributed computing, AI, or the intricacies of machine learning and LLMs, you'll find resources here that cater to a wide range of interests and skill levels.</p> <p>Beyond tutorials and guides, this space serves as a reflection of my personal journey and thoughts on where technology is headed. I believe in the power of sharing knowledge and experiences, and I hope to foster a community of like-minded individuals who are eager to learn, innovate, and contribute to the ever-evolving tech landscape.</p> <p>Stay connected and follow my journey:</p> <p>      LinkedIn    </p> <p>      GitHub    </p> <p>      Medium    </p>"},{"location":"spark/intro-spark/","title":"Introduction to Apache Spark","text":"<p>Apache Spark is an open-source, distributed computing system that provides an interface for programming entire clusters with implicit data parallelism and fault tolerance. Originally developed at UC Berkeley's AMPLab, Spark has rapidly become one of the most popular big data technologies in use today.</p>"},{"location":"spark/intro-spark/#key-features-of-apache-spark","title":"Key Features of Apache Spark","text":"<ul> <li>Speed: Spark enables applications in Hadoop clusters to run up to 100 times faster in memory and 10 times faster even when running on disk.</li> <li>Ease of Use: It offers over 80 high-level operators that make it easy to build parallel apps, and you can use it interactively from the Scala, Python, R, and SQL shells.</li> <li>Modular: Spark includes libraries for diverse tasks ranging from SQL to streaming and machine learning, making it a versatile tool for handling a wide array of data processing requirements.</li> </ul>"},{"location":"spark/intro-spark/#components-of-apache-spark","title":"Components of Apache Spark","text":"<ol> <li>Spark Core: The foundation of the system that provides distributed task dispatching, scheduling, and basic I/O functionalities.</li> <li>Spark SQL: Facilitates the processing of structured data and the capability to query the data using SQL, as well as Hive Query Language.</li> <li>Spark Streaming: Enables processing of real-time streaming data.</li> <li>MLlib: Spark\u2019s scalable machine learning library.</li> <li>GraphX: Supports graph processing to handle graph databases and perform graph-parallel computation.</li> </ol>"},{"location":"spark/intro-spark/#use-cases","title":"Use Cases","text":"<p>Apache Spark is employed across various industries for numerous applications. It's particularly favored for: - Real-time data processing and analytics. - Machine learning model development. - Data transformation and aggregation tasks.</p>"},{"location":"spark/intro-spark/#getting-started","title":"Getting Started","text":"<p>To get started with Apache Spark, you can download the latest version from the Apache Spark official website. For comprehensive guidance on installation and setup, the website and its documentation are invaluable resources.</p> <p>Feel free to explore the subsequent sections to dive deeper into Spark\u2019s capabilities and learn through examples and detailed explanations.</p>"}]}